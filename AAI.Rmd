---
title: "AAI"
output: 
  flexdashboard::flex_dashboard:
  orientation: columns
vertical_layout: fill
runtime: shiny
---
  
```{r, warning=FALSE, message=FALSE, error=FALSE}

# Load packages
library(flexdashboard)
library(tidyverse)
library(shiny)
library(DT)
library(gridExtra)
library(ggplot2)
library(pROC)
library(caret)

# Load data
X <- read_csv("PROCESSED_DATA/features_x.csv")  %>% arrange(date) %>% slice(1:2473)
colnames(X) <- c("Data","Dolar", "Euro", "Yuhan Chines", "Peso Argentino", "Gasolina", "Selic", "Cesta Básica")
Y <- read_csv("PROCESSED_DATA/targets_y.csv") %>%  arrange(date) %>%  slice(2:2474)

```

# Exploratória

Column {data-width=650}
-----------------------------------------------------------------------
  
### Gráfico de Dispersão Explicativa vs Explicativa
  
```{r}

# Define reactive object data
date1 <- reactive({
  
  # Filter date by input
  X <- X %>% filter(Data > input$date1[1], Data < input$date1[2]) 
  
  # Return filtered dates X and Y
  return(X)
  
})

```


```{r}

# Define target_feature scatterplot
renderPlot({
  
  # Retrive filtered data
  X <- date1()
  
  # Condition to scale data
  if(input$scale1 == "Original"){
    
    # Define target anf feature
    feature1 <- X[, input$feature1_1] %>% pull()
    feature2 <- X[, input$feature1_2] %>% pull()
    
    # Condition to scale data
  } else if(input$scale1 == "Padrão"){
    
    # Define target anf feature
    feature1 <- as.vector(scale(X[, input$feature1_1] %>% pull()))
    feature2 <- as.vector(scale(X[, input$feature1_2] %>% pull()))
    
  } else if(input$scale1 == "Logaritmo") {
    
    # Define target anf feature
    feature1 <- log(X[, input$feature1_1] %>% pull())
    feature2 <- log(X[, input$feature1_2] %>% pull())
    
  } 
  
  # Define date
  date <- X[, 1] %>% pull()
  
  # Calculate correlation
  correlation <- round(cor(feature1, feature2),4)
  
  # Define data frame
  df <- tibble(date = date,
               feature1 = feature1,
               feature2 = feature2)
  
  # Define plot
  p1 <- ggplot(df, aes(x = feature1,
                       y = feature2))+
    geom_point(size = 0.9, color = "#00BFC4")+
    geom_smooth(method = "lm")+
    labs(title = paste0("Série Histórica ",
                        input$feature1_1,
                        " vs ",
                        input$feature1_2,
                        " com Reta de Regresão Linear",
                        " - Correlação = ", correlation),
         x = input$feature1_1,
         y = input$feature1_2)
  
  # Define colnames
  colnames(df) <- c("Tempo",input$feature1_1,input$feature1_2)
  
  # Redefine df
  df <- df %>% 
    pivot_longer(-Tempo)
  
  # Define plot
  p2 <- ggplot(df, aes(x = Tempo,
                       y = value,
                       color = name))+
    geom_line(size = 1.1, alpha = 0.6)+
    labs(title = paste0("Série Histórica ",
                        input$feature1_1,
                        " , ",
                        input$feature1_2,
                        " vs ",
                        "Tempo"),
         x = "Tempo",
         y = "Valor",
         color = "Série")
  
  # Print plots
  grid.arrange(p1,p2, nrow = 2)
  
})

```

### Gráfico de Dispersão Resposta vs Explicativa

```{r}

# Define reactive object data
date2 <- reactive({
  
  # Filter date by input
  X <- X %>% filter(Data > input$date2[1], Data < input$date2[2]) 
  Y <- Y %>% filter(date > input$date2[1], date < input$date2[2]) 
  
  # Return filtered dates X and Y
  return(list(X, Y))
  
})

```


```{r}

# Define target_feature scatterplot
renderPlot({
  
  # Retrive filtered data
  X <- date2()[[1]]
  Y <- date2()[[2]]
  
  # Condition to scale data
  if(input$scale2 == "Original"){
    
    # Define target anf feature
    feature <- X[, input$feature1] %>% pull()
    target <- Y[, input$target1] %>% pull()
    
    # Condition to scale data
  } else if(input$scale2 == "Padrão"){
    
    # Define target anf feature
    feature <- as.vector(scale(X[, input$feature1] %>% pull()))
    target <- as.vector(scale(Y[, input$target1] %>% pull()))
    
  } else if(input$scale2 == "Logaritmo") {
    
    # Define target anf feature
    feature <- log(X[, input$feature1] %>% pull())
    target <- log(Y[, input$target1] %>% pull())
    
  } 
  
  # Define date vector
  date <- X[, 1] %>% pull()
  
  # Calculate correlation
  correlation <- round(cor(feature, target),4)
  
  # Define data frame
  df <- tibble(date = date,
               feature = feature,
               target = target)
  
  # Define plot
  p1 <- ggplot(df, aes(x = feature,
                       y = target))+
    geom_point(size = 0.9, color = "#00BFC4")+
    geom_smooth(method = "lm")+
    labs(title = paste0("Série Histórica ",
                        input$feature1,
                        " vs ",
                        input$target1,
                        " com Reta de Regresão Linear",
                        " - Correlação = ", correlation),
         x = input$feature1,
         y = input$target1)
  
  # Define colnames
  colnames(df) <- c("Tempo",input$feature1,input$target1)
  
  # Redefine df
  df <- df %>% 
    pivot_longer(-Tempo)
  
  # Define plot
  p2 <- ggplot(df, aes(x = Tempo,
                       y = value,
                       color = name))+
    geom_line(size = 1.1, alpha = 0.6)+
    labs(title = paste0("Série Histórica ",
                        input$feature1,
                        " , ",
                        input$target1,
                        " vs ",
                        "Tempo"),
         x = "Tempo",
         y = "Valor",
         color = "Série")
  
  # Print plots
  grid.arrange(p1,p2, nrow = 2)
  
})

```

Column {data-width=350}
-----------------------------------------------------------------------
  
### Seleção de Variáveis
  
```{r}

# Define features Inputs
selectInput("feature1_1",
            "Variável Explicativa",
            choices = colnames(X)[2:8],
            multiple = F)

# Define targets inputs
selectInput("feature1_2",
            "Variável Resposta",
            choices = colnames(X)[2:8],
            multiple = F,
            selected = "Euro")

# Define padronization
selectInput("scale1",
            "Transformação da Escala",
            choices = c("Original","Padrão", "Logaritmo"))

# Define data range
dateRangeInput("date1",
               "Amplitude da Série",
               min = "2012-01-02",
               max = "2021-06-30",
               start = "2012-01-02",
               end = "2021-06-30",
               language = "pt-BR",
               separator = "até")

```

### Seleção de Variáveis

```{r}

# Define features Inputs
selectInput("feature1",
            "Variável Explicativa",
            choices = colnames(X)[2:8],
            multiple = F)

# Define targets inputs
selectInput("target1",
            "Variável Resposta",
            choices = colnames(Y)[2:324] %>%  sort(),
            multiple = F)

# Define padronization
selectInput("scale2",
            "Transformação da Escala",
            choices = c("Original","Padrão", "Logaritmo"))

# Define data range
dateRangeInput("date2",
               "Amplitude da Série",
               min = "2012-01-02",
               max = "2021-06-30",
               start = "2012-01-02",
               end = "2021-06-30",
               language = "pt-BR",
               separator = "até")

```


# Regressão Linear

Column {data-width=650}
-----------------------------------------------------------------------
  
### Estatísticas dos Coeficientes Modelo
  
```{r}

# Define reactive object data
date3 <- reactive({
  
  # Filter date by input
  X <- X %>% filter(Data > input$date3[1], Data < input$date3[2])
  Y <- Y %>% filter(date > input$date3[1], date < input$date3[2]) 
  
  # Return filtered dates X and Y
  return(list(X, Y))
  
})

```


```{r}

# Define modelo de regressão linear
linear_reg <- reactive({
  
  # Retrive filtered data
  X <- date3()[[1]]
  Y <- date3()[[2]]
  
  # Define target anf feature
  feature <- scale(X[, input$feature2]) %>% as_tibble()
  target <- log(Y[, input$target2] %>% pull())
    
  # Define target df
  df_target <- tibble(target = target)
  
  # Define data frame
  df <- df_target %>% 
    bind_cols(feature)
  
  # Define train sample
  train_sample <- 1:(round(nrow(df) * input$train))
  
  # Define train and test
  train <- df[train_sample, ]
  test <- df[-train_sample, ]
  
  # Print Model
  model <- lm(target ~ ., data = train)
  
  # Return model
  return(model)
  
})

```


```{r}

# Define target_feature scatterplot
renderDT({
  
  # Print Model
  model <- summary(linear_reg())$coefficients %>% 
    as_tibble() %>% 
    round(6) %>% 
    rename(Estimativa = Estimate,
           `Erro Padrão` = "Std. Error",
           `T-Valor` = "t value",
           `P-Valor` = "Pr(>|t|)")
  
  # Define statistics
  stat <- tibble(`Estatística` = c("Intercepto", input$feature2))
  
  # Define results
  results <- stat %>%  
    bind_cols(model)
  
  # Print table
  datatable(results,
            options = list(dom = "t",
                           pageLength = 11,
                           scrollY = "185px"))
  
})

```

### Gráfico de Performance do Modelo no Tempo

```{r}

# Define target_feature scatterplot
renderPlot({
  
  # Retrive filtered data
  X <- date3()[[1]]
  Y <- date3()[[2]]
  
  # Define target anf feature
  feature <- scale(X[, input$feature2]) %>% as_tibble()
  target <- log(Y[, input$target2] %>% pull())
  
  # Define target df
  df_target <- tibble(target = target)
  
  # Define data frame
  df <- df_target %>% 
    bind_cols(feature)
  
  # Define train sample
  train_sample <- 1:(round(nrow(df)* input$train))
  
  # Define train and test
  train <- df[train_sample, ]
  test <- df[-train_sample, ]
  
  # Define date vector
  date_X <- X[, 1] %>% pull()
  
  # Define target df
  df_target <- tibble(target = target)
  
  # Define data frame
  df <- df_target %>% 
    bind_cols(feature)
  
  # Define Predictions
  pred_train <- exp(linear_reg()$fitted.values)
  pred_test <- exp(predict(linear_reg(), newdata = test[, -1]))
  date_test <- 1:(length(date_X) - length(train_sample))
  pred_test2 <- predict(loess(pred_test~date_test, span = input$loes))
  
  # Define series data frame
  df_serie <- tibble(date = date_X,
                     value = exp(df_target$target),
                     type = input$target2)
  
  # Define pred train data frame
  df_pred_train = tibble(date = date_X[train_sample],
                         value = pred_train,
                         type = "Preditos Treino")
  
  # Define pred test data frame
  df_pred_test = tibble(date = date_X[-train_sample],
                        value = pred_test2,
                        type = "Preditos Teste")
  
  # Combina data frames
  df_serie_train_test <- df_serie %>% 
    bind_rows(df_pred_train) %>% 
    bind_rows(df_pred_test) %>% 
    mutate(type = factor(type, levels = c(input$target2, "Preditos Treino", "Preditos Teste")))
  
  # Define plot
  ggplot(df_serie_train_test, aes(x = date, y = value, color = type))+
    geom_line(size = 1.05, alpha = 0.8)+
    labs(title = paste0("Gráfico das Séries ", input$target2, ", Preditos Treino e Preditos Teste vs Tempo"),
         x = "Tempo",
         y = paste("Valor (BRL)"),
         color = "Série")+
    scale_color_manual(values=c("black","#00BFC4", "#F8766D"))+
    theme(plot.title = element_text(hjust = 0.5))
  
})

```

### Gráficos de Resíduos Banco de Teste

```{r}

# Define target_feature scatterplot
renderPlot({
  
  # Retrive filtered data
  X <- date3()[[1]]
  Y <- date3()[[2]]
  
  # Define target anf feature
  feature <- scale(X[, input$feature2]) %>% as_tibble()
  target <- log(Y[, input$target2] %>% pull())
  
  # Define target df
  df_target <- tibble(target = target)
  
  # Define data frame
  df <- df_target %>% 
    bind_cols(feature)
  
  # Define train sample
  train_sample <- 1:(round(nrow(df)* input$train))
  
  # Define train and test
  train <- df[train_sample, ]
  test <- df[-train_sample, ]
  
  # Define target anf feature
  predicted <- predict(linear_reg(), newdata = test[, -1])
  targets <- test$target
  
  # Define data frame
  df_plot <- tibble(predicted = predicted,
                    observed = targets)
  
  # Define plot
  p1 <- ggplot(df_plot, aes(x = observed,
                            y = predicted))+
    geom_point(size = 0.9, color = "#00BFC4")+
    geom_abline(intercept = 0, slope = 1, color = "#F8766D")+
    labs(title = "Precisão",
         x = "Observados",
         y = "Preditos")+
    theme(plot.title = element_text(hjust = 0.5))
  
  # Define target anf feature
  predicted <- predict(linear_reg(), newdata = test[, -1])
  residuals <- predicted - test$target
  
  # Define data frame
  df1 <- tibble(Residuals = residuals,
                Fitted = predicted)
  
  # Define plot
  p2 <- ggplot(df1, aes(x = Fitted,
                        y = Residuals))+
    geom_point(size = 0.9, color = "#00BFC4")+
    geom_hline(yintercept = 0, color = "#F8766D")+
    labs(title = "Variância",
         x = "Preditos",
         y = "Resíduos")+
    theme(plot.title = element_text(hjust = 0.5))
  
  # Define data frame
  df2 <- tibble(Residuals = residuals)
  
  # Define plot
  p3 <- ggplot(df2, aes(x = Residuals))+
    geom_histogram(color = "black", fill = "#00BFC4")+
    labs(title = "Normalidade",
         x = "Resíduos",
         y = "Frequência")+
    theme(plot.title = element_text(hjust = 0.5))
  
  # Define data frame
  df3 <- tibble(Observations = 1:length(residuals),
                Residuals = residuals)
  
  # Define plot
  p4 <- ggplot(df3, aes(x = Observations, y = residuals))+
    geom_point(size = 0.9, color = "#00BFC4")+
    geom_hline(yintercept = 0, color = "#F8766D")+
    labs(title = "Independência",
         x = "Observações",
         y = "Resíduos")+
    theme(plot.title = element_text(hjust = 0.5))
  
  # Dsiplay plots with 2 columns arrange
  grid.arrange(p1, p2, p3, p4, ncol = 4)
  
})

```

Column {data-width=350}
-----------------------------------------------------------------------
  
```{r}

# Define features Inputs
selectInput("feature2",
            "Variáveis Explicativas",
            choices = colnames(X)[2:8],
            multiple = T)

# Define targets inputs
selectInput("target2",
            "Variável Resposta",
            choices = colnames(Y)[2:324] %>% sort(),
            multiple = F,
            selected = 1)

# Define train percentual
sliderInput("train",
            "Percentual Banco de Treino",
            min = 0.01,
            max = 0.99,
            value = 0.75)

# Define data range
dateRangeInput("date3",
               "Amplitude",
               min = "2012-01-02",
               max = "2021-06-30",
               start = "2012-01-02",
               end = "2021-06-30",
               language = "pt-BR",
               separator = "até")

# Define train percentual
sliderInput("loes",
            "Suavizador Loess",
            min = 0.01,
            max = 0.99,
            value = 0.25)

```


### Estatísticas do Modelo Banco de Treino

```{r}

# Define target_feature scatterplot
renderDT({
  
  # Retrive filtered data
  X <- date3()[[1]]
  Y <- date3()[[2]]
  
  # Define target anf feature
  feature <- scale(X[, input$feature2]) %>% as_tibble()
  target <- log(Y[, input$target2] %>% pull())
    
  # Define target df
  df_target <- tibble(target = target)
  
  # Define data frame
  df <- df_target %>% 
    bind_cols(feature)
  
  # Define train sample
  train_sample <- 1:(round(nrow(df)* input$train))
  
  # Define train and test
  train <- df[train_sample, ]
  test <- df[-train_sample, ]
  
  # Defne reqm
  rmse <- round(sqrt(mean(linear_reg()$residuals^2)), 6)
  
  # Print Model
  model_summary <- summary(linear_reg())
  
  # Define data frame of statistics
  df_stats <- tibble(`Estatística` = c("R2 Ajustado", "REQM", "AIC"),
                     Estimativa = round(c(model_summary$adj.r.squared,
                                          rmse,
                                          round(AIC(linear_reg()),2)), 6)) 
  
  # Imprime tabela
  datatable(df_stats, options = list(dom = "t", scrollY = "120px"))
  
})

```

### Estatísticas do Modelo Banco de Teste

```{r}

# Define target_feature scatterplot
renderDT({
  
  # Retrive filtered data
  X <- date3()[[1]]
  Y <- date3()[[2]]

  # Define target anf feature
  feature <- scale(X[, input$feature2]) %>% as_tibble()
  target <- log(Y[, input$target2] %>% pull())
  
  # Define target df
  df_target <- tibble(target = target)
  
  # Define data frame
  df <- df_target %>% 
    bind_cols(feature)
  
  # Define train sample
  train_sample <- 1:(round(nrow(df)* input$train))
  
  # Define train and test
  train <- df[train_sample, ]
  test <- df[-train_sample, ]
  
  # Define target anf feature
  predicted <- predict(linear_reg(), newdata = test[, -1])
  targets <- test$target
  
  # Calculate rmse
  residuals <- predicted - targets
  rmse <- round(sqrt(mean(residuals^2)),6)
  
  # Teste de Shapiro Wilkins
  test_shap <- round(shapiro.test(residuals)$p.value, 10)
  
  # Define data frame of statistics
  df_stats <- tibble(`Estatística` = c("REQM", "Resíduos Shapiro P-Valor"),
                     Estimativa = c(rmse,
                                    test_shap)) 
  
  # Imprime tabela
  datatable(df_stats, options = list(dom = "t", scrollY = "80px"))
  
})

```


# Otimização


Column {data-width=650}
-----------------------------------------------------------------------

### Estatísticas de Coeficientes do Modelo

```{r}

# Load data
X_opt <- read_csv("PROCESSED_DATA/features_x.csv")  %>% arrange(date) %>% slice(1:2473)
colnames(X_opt) <- c("Data","Dolar", "Euro", "Yuhan Chines", "Peso Argentino", "Gasolina", "Selic", "Cesta Básica")
Y_opt <- read_csv("PROCESSED_DATA/targets_y.csv") %>%  arrange(date) %>%  slice(2:2474)

# Define date ranges
date_range <- as.character(seq(as.Date("2012-01-03"), as.Date("2016-01-03"), by = "year"))

# Define lisp of combinations
combs_range <- list()

# Define combination of variables
for(i in 1:7){
  
  # Generate combinations aux variable
  aux <- combn(1:7, i) 
  
  # Loop to extract columns as vectors to the list
  for(comb in 1:ncol(aux))
  
    # Populate list
    combs_range <- append(combs_range, list(aux[, comb]))
  
}

# Split train test range
train_test_split <- seq(0.6, 0.9, by = 0.01)

```

```{r}

# Define modelo de regressão linear
optimization <- eventReactive(input$trigger,{
  
  # Preprocess data
  df_target <- Y_opt[, c("date", input$target10)] %>% 
    rename(target = input$target10) %>% 
    mutate(target = log(target)) %>% select(date, target)
  df_feature <- scale(X_opt[, -1]) %>% as_tibble()
  
  # Define data frame
  df <- df_target %>% 
          bind_cols(df_feature)
  
  # Define list of start dates
  model_df <- tibble(start_date = rep("2012-01-03",19685),
                     combs_range = rep(0, 19685), # rep("vars", 19685),
                     train_test_split = rep(0, 19685),
                     rmse = rep(0, 19685),
                     r2 = rep(0, 19685))
  
  # Define counter o models
  counter = 1
  
  # Define start time
  start_time <- Sys.time()
  
  # Loop over date range
  for(start_date in date_range){
    
    # Define matrix train test split as columns and variables combinations as rows
    mat_temp <- matrix(0, nrow = length(train_test_split), ncol = length(combs_range))
    
    # Set temporary dataframe 1
    df_temp1 <- df %>%  filter(date > start_date)
    
    # Loop over variables
    for(cr in 1:length(combs_range)){
      
      # Set temporary dataframe 2
      df_temp2 <- df_temp1[, c(2,(combs_range[[cr]] + 2))]
      
      # Loop over train_test_split
      for(tts in 1:length(train_test_split)){
        
        # Define train sample
        train_sample <- 1:(round(nrow(df_temp2) * train_test_split[tts] ))
        
        # Define train and test
        train <- df_temp2[train_sample, ]
        test <- df_temp2[-train_sample, ]
        
        # Print Model
        model <- lm(target ~ ., data = train)
        
        # Define predicted and target
        predicted <- predict(model, newdata = test[, -1])
        target <- test$target
        
        # Calculate rmse
        residuals <- predicted - target
        rmse <- round(sqrt(sum(residuals^2)) / (length(predicted) - length(model$coefficients)),6)
        
        # Populate model list
        model_df[counter, "start_date"] <- start_date
        model_df[counter, "combs_range"] <- cr 
        model_df[counter, "train_test_split"] <- train_test_split[tts]
        model_df[counter, "rmse"] <- rmse
        model_df[counter, "r2"] <- summary(model)$adj.r.squared
        
        # Increment couter
        counter <- counter + 1
        
        # Check Counter
        print(counter)
          
      }
      
    }
    
  }
  
  # Retrieve end_time
  end_time <- Sys.time()
  
  # Compute computer time
  results <- list(model_df, (end_time - start_time))
  
  # Define function return
  return(results)
  
})
  
```



```{r}

# Define modelo de regressão linear
linear_reg2 <- eventReactive(input$trigger,{
  
  # Preprocess target data
  df_target <- Y_opt[, c("date", input$target10)] %>% 
    rename(target = input$target10) %>% 
    mutate(target = log(target)) %>% select(date, target)
  
  # Pre process features data
  df_feature <- scale(X_opt[, -1]) %>% as_tibble()
  
  # Define data frame
  df <- df_target %>% 
          bind_cols(df_feature)
  
  # Retrieve model_df
  model_df <- optimization()[[1]]
  
  # Retrieve best model params
  best_model <- model_df[model_df$rmse == min(model_df$rmse),]
  
  # Set temporary dataframe 1
  df_temp1 <- df %>%  filter(date > best_model$start_date)
  
  # Set temporary dataframe 2
  df_temp2 <- df_temp1[, c(2,(combs_range[[best_model$combs_range]] + 2))]
  
  # Define train sample
  train_sample <- 1:(round(nrow(df_temp2) * best_model$train_test_split ))
  
  # Define train and test
  train <- df_temp2[train_sample, ]
  test <- df_temp2[-train_sample, ]
  
  # Compute Model
  model <- lm(target ~ ., data = train)
    
  # Return model
  return(model)
        
})

```



```{r}

# Define target_feature scatterplot
renderDT({
    
    # Print Model
    model <- summary(linear_reg2())$coefficients %>% 
      as_tibble() %>% 
      round(6) %>% 
      rename(Estimativa = Estimate,
             `Erro Padrão` = "Std. Error",
             `T-Valor` = "t value",
             `P-Valor` = "Pr(>|t|)")
    
    # Define coefficients names
    names_temp <- row.names(summary(linear_reg2())$coefficients) %>% str_remove_all("`")
    coef_names <- c("Intercepto", names_temp[2:length(names_temp)])
    
    # Define statistics
    coefs <- tibble(`Estatística` = coef_names)
    
    # Define results
    results <- coefs %>%  
                 bind_cols(model)
    
    # Print table
    datatable(results,
              options = list(dom = "t",
                             pageLength = 7,
                             scrollY = "190px"))
        
})

```

### Gráfico das Séries da Ação e Performances do Modelo no Tempo

```{r}

# Define plot data event reaction 
plot_react1 <- eventReactive(input$loess2,{
  
  # Preprocess data
  df_target <- Y_opt[, c("date", input$target10)] %>% 
    rename(target = input$target10) %>% 
    mutate(target = log(target)) %>% select(date, target)
  df_feature <- scale(X_opt[, -1]) %>% as_tibble()
  
  # Define data frame
  df <- df_target %>% 
          bind_cols(df_feature)
  
  # Retrieve model_df
  model_df <- optimization()[[1]]
  
  # Retrieve best model params
  best_model <- model_df[model_df$rmse == min(model_df$rmse),]
  
  # Set temporary dataframe 1
  df_temp1 <- df %>%  filter(date > best_model$start_date)
  
  # Set temporary dataframe 2
  df_temp2 <- df_temp1[, c(2,(combs_range[[best_model$combs_range]] + 2))]
  
  # Define train sample
  train_sample <- 1:(round(nrow(df_temp2) * best_model$train_test_split ))
  
  # Define train and test
  train <- df_temp2[train_sample, ]
  test <- df_temp2[-train_sample, ]
    
  # Compute Model
  model <- lm(target ~ ., data = train)
  
  # Define Predictions
  pred_train <- model$fitted.values
  pred_test <- predict(model, newdata = test[, -1])
  date <- df_target %>%  filter(date > best_model$start_date) %>% pull(date)
  date_test <- 1:(length(date) - length(train_sample))
  pred_test2 <- predict(loess(pred_test~date_test, span = input$loes2))
  target <- df_target %>%  filter(date > best_model$start_date) %>% pull(target)
  
  # Define series data frame
  df_serie <- tibble(date = date,
                     value = exp(target),
                     type = input$target10)
  
  # Define pred train data frame
  df_pred_train = tibble(date = date[train_sample],
                         value = exp(pred_train),
                         type = "Preditos Treino")
  
  # Define pred test data frame
  df_pred_test = tibble(date = date[-train_sample],
                        value = exp(pred_test2),
                        type = "Preditos Teste")
  
  # Combina data frames
  df_serie_train_test <- df_serie %>% 
    bind_rows(df_pred_train) %>% 
    bind_rows(df_pred_test) %>% 
    mutate(type = factor(type, levels = c(input$target10, "Preditos Treino", "Preditos Teste")))
  
  # Define plot
  p1 <- ggplot(df_serie_train_test, aes(x = date, y = value, color = type))+
    geom_line(size = 1.05, alpha = 0.8)+
    labs(title = paste0(input$target10, ",",
                        " Preditos Treino (",
                        best_model$train_test_split * 100,
                        "%) e Teste (",
                        100 - (best_model$train_test_split * 100),
                        "%) vs Tempo (",
                        format(as.Date(best_model$start_date), "%Y/%m"), " - ",
                        format(as.Date("2021-06-29"), "%Y/%m"), ")"),
         x = "Tempo",
         y = "Valor (BRL)",
         color = "Série")+
    scale_color_manual(values=c("black","#00BFC4", "#F8766D"))+
    theme(plot.title = element_text(hjust = 0.5))
  
  # Define fuction return
  return(p1)
  
}) 

```

```{r}

# Define target_feature scatterplot
renderPlot({
  
  # Retrive plot data
  plot_react1()
  
})

```


### Gráficos da Otimização 

```{r}

# Define plot data event reaction 
plot_react2 <- eventReactive(input$trigger,{
  
  # Retrieve model_df
  model_df <- optimization()[[1]]
  
  # Define surface data frame
  surface_df <- model_df %>% 
                  arrange(rmse) %>% 
                  mutate(rmse_scale = (rmse - min(rmse)) / (max(rmse) - min(rmse))) %>% 
                  mutate(objective = rmse_scale - r2)
  
  # Define tibble with best model
  opt_model <- surface_df %>%  filter(objective == min(objective))
  
  # Draw surface plot
  p1 <- ggplot(surface_df, aes(rmse, r2))+
    geom_point(alpha = 0.8, color = "#00BFC4")+
    geom_point(data = opt_model, aes(x = rmse, y = r2), color = "#F8766D", size = 3)+
    labs(title = "Gráfico de Dispersão REQM vs R2 Ajustado",
         x = "REQM",
         y = "R2 Ajustado")+
    theme(plot.title = element_text(hjust = 0.5))
  
  # Function return
  return(p1)
  
}) 

```


```{r}

# Define target_feature scatterplot
renderPlot({
  
  # Retrive plot data
  plot_react2()
  
})

```


Column {data-width=350}
-----------------------------------------------------------------------

```{r}

# Define targets inputs
selectInput("target10",
            "Variável Resposta",
            choices = colnames(Y_opt)[2:324] %>% sort(),
            multiple = F,
            selected = 1)

# Define train percentual
sliderInput("loes2",
            "Suavizador Loess",
            min = 0.01,
            max = 0.99,
            value = 0.25)

# Trigger button
actionButton("trigger", "Otimize",
             style="color: #fff; background-color: #337ab7; border-color: #2e6da4")

```


### Estatísticas do Modelo Banco de Treino

```{r}

# Define target_feature scatterplot
renderDT({
  
  # Print Model
  model_summary <- summary(linear_reg2())
  
  # Define rmse
  rmse <- round(sqrt(mean(linear_reg2()$residuals^2)),4)
  
  # Define data frame of statistics
  df_stats <- tibble(`Estatística` = c("R2 Ajustado", "REQM", "AIC"),
                     Estimativa = round(c(model_summary$adj.r.squared,
                                          rmse,
                                          round(AIC(linear_reg2()),2)), 6)) 
  
  # Imprime tabela
  datatable(df_stats, options = list(dom = "t", scrollY = "120px"))
  
})

```


### Estatísticas do Modelo Banco de Teste

```{r}

# Define table model test data event reaction 
table_react1 <- eventReactive(input$trigger,{
 
  # Preprocess data
  df_target <- Y_opt[, c("date", input$target10)] %>% 
    rename(target = input$target10) %>% 
    mutate(target = log(target)) %>% select(date, target)
  df_feature <- scale(X_opt[, -1]) %>% as_tibble()
  
  # Define data frame
  df <- df_target %>% 
          bind_cols(df_feature)
  
  # Retrieve model_df
  model_df <- optimization()[[1]]
  
  # Retrieve best model params
  best_model <- model_df[model_df$rmse == min(model_df$rmse),]
  
  # Set temporary dataframe 1
  df_temp1 <- df %>%  filter(date > best_model$start_date)
  
  # Set temporary dataframe 2
  df_temp2 <- df_temp1[, c(2,(combs_range[[best_model$combs_range]] + 2))]
  
  # Define train sample
  train_sample <- 1:(round(nrow(df_temp2) * best_model$train_test_split ))
  
  # Define train and test
  train <- df_temp2[train_sample, ]
  test <- df_temp2[-train_sample, ]
    
  # Define target anf feature
  predicted <- predict(linear_reg2(), newdata = test[, -1])
  targets <- test$target
  
  # Calculate rmse
  residuals <- predicted - targets
  rmse <- round(sqrt(mean(residuals^2)),6)
  
  # Shapiro Wilkins test
  test_shap <- round(shapiro.test(residuals)$p.value, 10)
  
  # Define data frame of statistics
  df_stats <- tibble(`Estatística` = c("REQM", "Resíduos Shapiro P-Valor"),
                     Estimativa = c(rmse,
                                    test_shap)) 
  
  # Return df_stats
  return(df_stats)
   
})

```



```{r}

# Define target_feature scatterplot
renderDT({
  
  # Print table
  datatable(table_react1(), options = list(dom = "t", scrollY = "80px"))
  
})

```

### 

```{r}

# Render valuebox
renderValueBox({
    shinydashboard::valueBox(
      value = paste0(round(optimization()[[2]],4)," Segundos"),
      subtitle = "Custo Computacional",
      icon = icon("clock", lib = "font-awesome"),
      color = "aqua",
      width = 6
    )
})

```


